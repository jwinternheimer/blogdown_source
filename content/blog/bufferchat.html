---
date: 2017-10-26T16:27:54-04:00
subtitle: ""
type: "post"
tags: []
title: "An analysis of #bufferchat tweets"
---



<p>Every week Buffer hosts an hour long discussion on twitter called <a href="https://buffer.com/bufferchat">Bufferchat</a>, in which participants talk about social media, productivity, and occasionally self-care. The topics change from week to week, and there is often a guest host that moderates.</p>
<div class="figure">
<img src="http://hi.buffer.com/2h0M1C010R0z/Screen%20Shot%202017-10-26%20at%204.36.57%20PM.png" />

</div>
<p>People join the chat from around the world. Many industries and company types are represented. This week, I thought it would be fun to collect the tweets and do some basic analysis on them.</p>
<div id="collecting-the-tweets" class="section level3">
<h3>Collecting the tweets</h3>
<p>We can use the <code>rtweet</code> package from Michael Kearney to collect the tweets. For this analysis, I connected to Twitter’s streaming API to collect all tweets containing the hashtag “#bufferchat”, but you could also do a basic search to grab the last n tweets containing the term.</p>
<p>To access the API, you’ll need to create an app at apps.twitter.com and obtain your API keys.</p>
<pre class="r"><code># load packages
library(rtweet); library(dplyr); library(lubridate); library(ggplot2)

# create access token
# twitter_token &lt;- create_token(app = &quot;julian_rtweet_app&quot;,
#                              consumer_key = Sys.getenv(&quot;TWITTER_API_CLIENT_ID&quot;), 
#                              consumer_secret = Sys.getenv(&quot;TWITTER_API_CLIENT_SECRET&quot;))

# save token
# saveRDS(twitter_token, &quot;~/.rtweet-oauth.rds&quot;)</code></pre>
<p>Now that we’ve created an access token, we can specify the parameters to capture a live stream of tweets from Twitter’s REST API. By default, the <code>stream_tweets</code> function will stream for 30 seconds and return a random sample of tweets. To modify the default settings, <code>stream_tweets</code> accepts several parameters, including <code>q</code> (query used to filter tweets), <code>timeout</code> (duration or time of stream in seconds), and <code>file_name</code> (path name for saving raw json data).</p>
<pre class="r"><code># specify parameters for twitter stream
keywords &lt;- &quot;#bufferchat&quot;
streamtime &lt;- 60 * 70
filename &lt;- &quot;bufferchat.json&quot;</code></pre>
<p>Once the parameters are set, we can initiate the stream.</p>
<pre class="r"><code># stream tweets
tweets_json &lt;- stream_tweets(q = keywords, timeout = streamtime, file_name = filename)

# parse from json file
tweets &lt;- parse_stream(filename)</code></pre>
<p>Awesome, we have 1377 tweets from this week’s Bufferchat. Here is a sample of what the data looks like.</p>
<pre class="r"><code>head(tweets %&gt;% select(screen_name:status_id))</code></pre>
<pre><code>##       screen_name    user_id          created_at          status_id
## 1 TheEventsSeeker  724335139 2017-10-25 15:50:46 923215265453633537
## 2     auraeleonor  136499071 2017-10-25 15:50:56 923215306738290688
## 3     MalharBarai   57591036 2017-10-25 15:51:32 923215460035837952
## 4   digitalpratik 3184398348 2017-10-25 15:52:11 923215623106080768
## 5  Haylee_Cornett  202346411 2017-10-25 15:52:29 923215699069276160
## 6       DewiEirig   19086504 2017-10-25 15:52:48 923215778702340096</code></pre>
<p>We can extract data about the users that sent the tweets as well.</p>
<pre class="r"><code># get user data
users &lt;- users_data(tweets)</code></pre>
<p>Now, let’s do some exploratory analysis.</p>
</div>
<div id="graphs-and-things" class="section level3">
<h3>Graphs and things</h3>
<p>Once parsed, the <code>ts_plot()</code> function provides a quick visual of the frequency of tweets. By default, <code>ts_plot()</code> will try to aggregate time by the day, but we can aggregate by minute instead.</p>
<pre class="r"><code># plot frequency of tweets
ts_plot(tweets, by = &quot;minutes&quot;)</code></pre>
<p><img src="/blog/bufferchat_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Today’s bufferchat was scheduled to begin at 12:00pm ET and last for one hour. I turned the stream on shortly before 12 and left it on for 70 minutes. We can see that the frequncy of tweets picks up shortly after 12 and starts to decline around 12:40pm.</p>
<p>We can see that there are distinct local peaks in this time series. I have a suspicion that these occur around the time that the Buffer twitter account releases the questions. Let’s try to plot these times on the same plot. To get these times, we’ll filter our tweets to only include tweets from the Buffer account that were not replies (there are lots of replies).</p>
<pre class="r"><code># get buffer tweets
tweets %&gt;%
  filter(screen_name == &#39;buffer&#39; &amp; is.na(in_reply_to_status_user_id)) %&gt;%
  select(text)</code></pre>
<pre><code>##                                                                                                                                                      text
## 1        Welcome to #bufferchat! (This is the 2nd of 2 chats this week) Anyone joining in the chat for the first time? \U0001f60a https://t.co/6bjHNRtdOY
## 2  Let’s kick off #bufferchat with an icebreaker! Where are you tweeting from &amp;amp; what&#39;s one of your favorite teams? \U0001f914 https://t.co/NeBmwfaYTB
## 3             Quick #bufferchat ask: up for including “A1, A2…” in your answer tweets? We’d love to include your insights in our… https://t.co/Tdm3TDLAKe
## 4                                     Q1: How many people are on your particular team? Does your team have a name? :) #bufferchat https://t.co/jbJd41ZLkP
## 5                                       Q2: Who do you work most closely with on your team? How do you work together? #bufferchat https://t.co/BFMRMcDphY
## 6                     Q3: Anyone have great tips for structuring meetings or brainstorms with your team? What works really well?… https://t.co/6VZRr8HMQR
## 7                                           Q4: What are some awesome tools that support team collaboration, and how? #bufferchat https://t.co/IgUaAEXlUJ
## 8                                                 Q5: What’s your advice for working through conflicts within a team? #bufferchat https://t.co/t16hLcffCg
## 9                                  Q6: What are some ideal ways for a team to get to know each other and build trust? #bufferchat https://t.co/U3u0yBKNc9
## 10                                                 Q7: Do you have any awesome team collaboration successes to share? #bufferchat https://t.co/RQaCNeY7sO
## 11                                                     Bonus! How would you summarize today’s #bufferchat learnings in one tweet? https://t.co/dsGeb2Xwdr
## 12             Thank you all so much for your awesome insights! Look for our #bufferchat recap here soon: https://t.co/a3JgZpWTMa https://t.co/H0nN0TXJjD</code></pre>
<p>That’s them! Let’s grab the times of these tweets.</p>
<p><img src="/blog/bufferchat_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The red dashed lines represent the times in which the Buffer account tweeted a question or announcement. We can see that in the minutes following a tweet, there tended to be an increase in activity.</p>
</div>
<div id="sentiment-analysis" class="section level3">
<h3>Sentiment analysis</h3>
<p>The Buffer team is the happiest group of people I’ve been around, and it shows in our communication. I would guess that the bufferchat tweets have very high sentiment scores – let’s check and see.</p>
<pre class="r"><code># we&#39;ll use the tidytext package
library(tidytext); library(tidyr)

# unnest tokens
words &lt;- tweets %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words, by = &#39;word&#39;)</code></pre>
<p>As discussed above, there are a variety of methods and dictionaries that exist for evaluating the opinion or emotion in text. The tidytext package contains several sentiment lexicons in the sentiments dataset.</p>
<pre class="r"><code>sentiments</code></pre>
<pre><code>## # A tibble: 23,165 x 4
##           word sentiment lexicon score
##          &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
##  1      abacus     trust     nrc    NA
##  2     abandon      fear     nrc    NA
##  3     abandon  negative     nrc    NA
##  4     abandon   sadness     nrc    NA
##  5   abandoned     anger     nrc    NA
##  6   abandoned      fear     nrc    NA
##  7   abandoned  negative     nrc    NA
##  8   abandoned   sadness     nrc    NA
##  9 abandonment     anger     nrc    NA
## 10 abandonment      fear     nrc    NA
## # ... with 23,155 more rows</code></pre>
<p>The three general-purpose lexicons are:</p>
<ul>
<li><code>AFINN</code> from Finn Årup Nielsen</li>
<li><code>bing</code> from Bing Liu and collaborators</li>
<li><code>nrc</code> from Saif Mohammad and Peter Turney</li>
</ul>
<p>We’ll use the <code>bing</code> lexicon to plot general sentiment, which is essentially positive - negative sentiment.</p>
<pre class="r"><code>sentiment &lt;- words %&gt;%
  mutate(created_at_minute = floor_date(created_at, unit = &quot;minutes&quot;)) %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;), by = &#39;word&#39;) %&gt;%
  count(created_at_minute, sentiment) %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(sentiment = positive - negative)</code></pre>
<p>Now we can plot these sentiment scores across the entirety of the chat.</p>
<p><img src="/blog/bufferchat_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>I refuse to believe that there are even minutes in which there are more negative tweets than positive, so let’s take a look at some of these so-called “negative” tweets’s text.</p>
<blockquote>
<p><span class="citation">@buffer</span> I’ve seen #bufferchat before but always seem to miss them. This is my first.</p>
</blockquote>
<p>This isn’t negative, but I see why our approach might classify it as negative.</p>
<blockquote>
<p><span class="citation">@SamanthaS_PR</span> <span class="citation">@buffer</span> Hello! This is only my third #bufferchat but I am a bit addicted… be warned</p>
</blockquote>
<p>This one also isn’t negative, but does include a couple of words that could be described as negative. It’s more playful than anything.</p>
<blockquote>
<p>Missed the Periscope. It wouldn’t load…</p>
</blockquote>
<p>Fine. Maybe there is one negative tweet. You get the idea!</p>
</div>
<div id="mapping-the-tweets" class="section level3">
<h3>Mapping the tweets</h3>
<p>I’ve always thought that it fun to map where the tweets come from. In the end, we’ll be able to create a map like this one.</p>
<div class="figure">
<img src="http://hi.buffer.com/0u1I0F2M0S2I/Screen%20Shot%202017-10-25%20at%206.53.28%20PM.png" />

</div>
<p>We’ll need to use the <code>location</code> field in the <code>users</code> data frame that we created earlier. In order to get the coordinates for these locations, we’ll use <a href="https://developers.google.com/maps/documentation/geocoding/start">Google Maps’ geocoding API</a>. It is very helpful to go there and get an API key.</p>
<p>The code below sets up a funcion we can call to call the API for each location in the <code>users</code> dataset.</p>
<pre class="r"><code>library(RCurl)
library(RJSONIO)
library(plyr)

# build URL to access api
url &lt;- function(address, return.call = &quot;json&quot;, sensor = &quot;false&quot;) {
  
  key &lt;- Sys.getenv(&#39;GEOCODE_API_KEY&#39;)
  
  root &lt;- &quot;https://maps.google.com/maps/api/geocode/&quot;
  u &lt;- paste(root, return.call, &quot;?address=&quot;, address, &quot;&amp;key=&quot;, key, &quot;&amp;sensor=&quot;, sensor, sep = &quot;&quot;)
  
  return(URLencode(u))
}

# function to parse the results:
geoCode &lt;- function(address, verbose = FALSE) {
  
  if(verbose) cat(address, &quot;\n&quot;)
  u &lt;- url(address)
  doc &lt;- getURL(u)
  x &lt;- fromJSON(doc,simplify = FALSE)
  print(x$status)
  
  if(x$status == &quot;OK&quot;) {
    
    lat &lt;- x$results[[1]]$geometry$location$lat
    lng &lt;- x$results[[1]]$geometry$location$lng
    location_type  &lt;- x$results[[1]]$geometry$location_type
    formatted_address  &lt;- x$results[[1]]$formatted_address
    
    return(c(lat, lng, location_type, formatted_address))
    Sys.sleep(0.5)
    
  } else {
    
    return(c(NA,NA,NA, NA))
    
  }
}

# function to get coordinates
get_coordinates &lt;- function(locations) {
  
  # apply geCode function to all locations
  coordinates  &lt;- ldply(locations, function(x) geoCode(x))
  
  # rename columns
  names(coordinates)  &lt;- c(&quot;lat&quot;,&quot;lon&quot;,&quot;location_type&quot;, &quot;formatted&quot;)
  
  # set latitude and longitude as numeric
  coordinates$lat &lt;- as.numeric(coordinates$lat)
  coordinates$lon &lt;- as.numeric(coordinates$lon)
  
  # return dataframe
  return(coordinates)
}</code></pre>
<p>To get the coordinates for these bufferchat users, we can use the following two commands.</p>
<pre class="r"><code># get locations of users
locations &lt;- users[!is.na(users$location),]$location

# geocode vector with addresses
coordinates &lt;- get_coordinates(locations)</code></pre>
<p>Now we can build the map!</p>
<pre class="r"><code># get world map
library(ggalt); library(ggthemes)

# get world map
world &lt;- map_data(&quot;world&quot;)
world &lt;- world[world$region != &quot;Antarctica&quot;,]

# plot tweets on a world map
ggplot() + 
  geom_map(data = world, map = world, aes(x = long, y = lat, map_id = region), 
           color=&quot;white&quot;, fill=&quot;#7f7f7f&quot;, size=0.05, alpha=1/4) +
  geom_point(data = coordinates, aes(x = lon, y = lat), alpha = 0.3, size = 2, position = &#39;jitter&#39;) +
  scale_color_tableau() +
  coord_proj(&quot;+proj=wintri&quot;) +
  theme(strip.background=element_blank()) +
  theme_map() </code></pre>
<div class="figure">
<img src="http://hi.buffer.com/0u1I0F2M0S2I/Screen%20Shot%202017-10-25%20at%206.53.28%20PM.png" />

</div>
<p>And that’s it! What do you all think? Anything else you’d like to see?</p>
</div>
